using System.ComponentModel;
using System.ComponentModel.DataAnnotations;
using System.Net.Http.Headers;
using System.Runtime.Serialization;
using System.Text.Json;
using System.Text.Json.Serialization;
using MCPhappey.Common.Extensions;
using MCPhappey.Core.Extensions;
using MCPhappey.Core.Services;
using Microsoft.Extensions.DependencyInjection;
using Microsoft.KernelMemory.Pipeline;
using ModelContextProtocol.Protocol;
using ModelContextProtocol.Server;

namespace MCPhappey.Tools.AIML.Music;

public static class AIMLMusic
{
    private static readonly string BASE_URL = "https://api.aimlapi.com/v2/generate/audio";

    [Description("Generate a music track using Google's Lyria 2 model. The model creates high-quality music from textual prompts.")]
    [McpServerTool(
         Title = "Generate music with Google Lyria 2",
         Name = "aiml_music_lyria2_generate",
         Destructive = false)]
    public static async Task<CallToolResult?> AIMLMusic_Lyria2Generate(
         [Description("Prompt describing the music to generate. Include style, mood, instruments, etc."), MaxLength(4000)] string prompt,
         IServiceProvider serviceProvider,
         RequestContext<CallToolRequestParams> requestContext,
         [Description("Elements or characteristics to exclude from the generated music.")] string? negativePrompt = null,
         [Description("Seed for deterministic generation (optional).")] int? seed = null,
         [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
         CancellationToken cancellationToken = default)
         => await requestContext.WithExceptionCheck(async () =>
     {
         var settings = serviceProvider.GetRequiredService<AIMLSettings>();
         var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();

         // Step 1: Ask user for any missing fields
         var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
             new AIMLLyria2MusicRequest
             {
                 Prompt = prompt,
                 NegativePrompt = negativePrompt,
                 Seed = seed,
                 Filename = filename?.ToOutputFileName() ?? requestContext.ToOutputFileName("mp3")
             },
             cancellationToken);

         // Step 2: Build JSON payload
         var body = new
         {
             model = "google/lyria2",
             prompt = typed.Prompt,
             negative_prompt = typed.NegativePrompt,
             seed = typed.Seed
         };

         var aiml = serviceProvider.GetRequiredService<AIMLClient>();
         var doc = await aiml.PostAsync(BASE_URL, body, cancellationToken);
         var id = doc.RootElement.TryGetProperty("id", out var idProp)
             ? idProp.GetString()
             : null;

         if (string.IsNullOrWhiteSpace(id))
             throw new Exception("No generation ID returned from Lyria API.");

         return doc.ToJsonContent(MINIMAX_UPLOAD_URL).ToCallToolResult();
     });

    [Description("Please fill in the AI/ML Lyria 2 music generation request.")]
    public class AIMLLyria2MusicRequest
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("The main prompt describing the desired music (genre, mood, instrumentation, etc.).")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("negative_prompt")]
        [Description("Elements or characteristics to exclude from the generated music.")]
        public string? NegativePrompt { get; set; }

        [JsonPropertyName("seed")]
        [Description("Seed for deterministic generation (optional).")]
        public int? Seed { get; set; }

        [JsonPropertyName("filename")]
        [Required]
        [Description("Output filename without extension.")]
        public string Filename { get; set; } = default!;
    }

    [Description("Generate a music track using ElevenLabs' AI Music model (eleven_music). Describe genre, mood, tempo, or include lyrics directly in the prompt.")]
    [McpServerTool(
       Title = "Generate music with ElevenLabs Music",
       Name = "aiml_music_elevenlabs_generate",
       Destructive = false)]
    public static async Task<CallToolResult?> AIMLMusic_ElevenLabsGenerate(
       [Description("Prompt describing the music to generate (genre, mood, vocals, tempo, lyrics, etc.)."), MaxLength(2000)] string prompt,
       IServiceProvider serviceProvider,
       RequestContext<CallToolRequestParams> requestContext,
       [Description("Desired music length in milliseconds (min 10000, max 300000).")] int musicLengthMs = 10000,
       [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
       CancellationToken cancellationToken = default)
       => await requestContext.WithExceptionCheck(async () =>
   {
       var settings = serviceProvider.GetRequiredService<AIMLSettings>();
       var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();

       // Step 1: Ask user for any missing input
       var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
           new AIMLElevenLabsMusicRequest
           {
               Prompt = prompt,
               MusicLengthMs = musicLengthMs,
               Filename = filename?.ToOutputFileName() ?? requestContext.ToOutputFileName("mp3")
           },
           cancellationToken);

       // Step 2: Build JSON payload
       var body = new
       {
           model = "elevenlabs/eleven_music",
           prompt = typed.Prompt,
           music_length_ms = typed.MusicLengthMs
       };

       var aiml = serviceProvider.GetRequiredService<AIMLClient>();
       var doc = await aiml.PostAsync(BASE_URL, body, cancellationToken);
       var id = doc.RootElement.TryGetProperty("id", out var idProp)
           ? idProp.GetString()
           : null;

       if (string.IsNullOrWhiteSpace(id))
           throw new Exception("No generation ID returned from ElevenLabs Music API.");

       // Step 5: Return raw JSON + info message
       return doc.ToJsonContent(BASE_URL).ToCallToolResult();
   });

    [Description("Please fill in the ElevenLabs music generation request.")]
    public class AIMLElevenLabsMusicRequest
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("Describe the desired music: genre, mood, tempo, instruments, and optional lyrics.")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("music_length_ms")]
        [Range(10000, 300000)]
        [Description("Desired music length in milliseconds (min 10s, max 5min).")]
        public int MusicLengthMs { get; set; } = 10000;

        [JsonPropertyName("filename")]
        [Required]
        [Description("The output filename without extension.")]
        public string Filename { get; set; } = default!;
    }


    private static readonly string MINIMAX_UPLOAD_URL = "https://api.aimlapi.com/v2/generate/audio/minimax/upload";
    private static readonly string MINIMAX_GENERATE_URL = "https://api.aimlapi.com/v2/generate/audio/minimax/generate";

    // --- 1️⃣ Upload reference track ---
    [Description("Uploads a reference track (song, voice, or instrumental) to MiniMax for analysis, producing reusable voice_id and/or instrumental_id.")]
    [McpServerTool(
        Title = "Upload reference music for MiniMax",
        Name = "aiml_music_minimax_upload",
        Destructive = false)]
    public static async Task<CallToolResult?> AIMLMusic_MiniMaxUpload(
        [Description("Input file URL. Protected SharePoint and/or OneDrive links are supported.")] string fileUrl,
        [Description("Purpose of upload: song, voice, or instrumental.")] UploadPurpose purpose,
        IServiceProvider serviceProvider,
        RequestContext<CallToolRequestParams> requestContext,
        CancellationToken cancellationToken = default)
        => await requestContext.WithExceptionCheck(async () =>
    {
        var settings = serviceProvider.GetRequiredService<AIMLSettings>();
        var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();
        var downloadService = serviceProvider.GetRequiredService<DownloadService>();

        // Step 1: Download file
        var files = await downloadService.DownloadContentAsync(serviceProvider, requestContext.Server, fileUrl, cancellationToken);
        var file = files.FirstOrDefault() ?? throw new Exception("File not found.");

        // Step 2: Ask for confirmation via elicitation (optional)
        var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
            new AIMLMiniMaxUploadRequest
            {
                FileUrl = fileUrl,
                Purpose = purpose
            },
            cancellationToken);

        // Step 3: Build multipart body (binary upload)
        using var client = clientFactory.CreateClient();
        using var form = new MultipartFormDataContent
        {
            { new ByteArrayContent(file.Contents.ToArray()), "file", file.Filename ?? "upload.mp3" },
            { new StringContent(typed.Purpose.ToString().ToLowerInvariant()), "purpose" }
        };

        using var request = new HttpRequestMessage(HttpMethod.Post, MINIMAX_UPLOAD_URL);
        request.Headers.Authorization = new AuthenticationHeaderValue("Bearer", settings.ApiKey);
        request.Headers.Accept.Add(new MediaTypeWithQualityHeaderValue(MimeTypes.Json));
        request.Content = form;

        // Step 4: Send request
        using var resp = await client.SendAsync(request, cancellationToken);
        var jsonResponse = await resp.Content.ReadAsStringAsync(cancellationToken);
        if (!resp.IsSuccessStatusCode)
            throw new Exception($"{resp.StatusCode}: {jsonResponse}");

        // Step 5: Return JSON result
        using var doc = JsonDocument.Parse(jsonResponse);
        return doc.ToJsonContent(MINIMAX_UPLOAD_URL).ToCallToolResult();
    });

    // --- 2️⃣ Generate music from reference ---
    [Description("Generates a new music sample using MiniMax based on previously uploaded voice/instrumental references and optional lyrics.")]
    [McpServerTool(
        Title = "Generate music with MiniMax",
        Name = "aiml_music_minimax_generate",
        Destructive = false)]
    public static async Task<CallToolResult?> AIMLMusic_MiniMaxGenerate(
        IServiceProvider serviceProvider,
        RequestContext<CallToolRequestParams> requestContext,
        [Description("Lyrics or song content. You can include formatting (## for accompaniment, newlines for pauses)."), MaxLength(600)] string lyrics,
        [Description("Reference voice ID (optional). Returned from MiniMax upload step.")] string? referVoice = null,
        [Description("Reference instrumental ID (optional). Returned from MiniMax upload step.")] string? referInstrumental = null,
        [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
        CancellationToken cancellationToken = default)
        => await requestContext.WithExceptionCheck(async () =>
    {
        var settings = serviceProvider.GetRequiredService<AIMLSettings>();
        var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();

        // Step 1: Elicit missing params
        var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
            new AIMLMiniMaxGenerateRequest
            {
                Lyrics = lyrics,
                ReferVoice = referVoice,
                ReferInstrumental = referInstrumental,
                Filename = filename?.ToOutputFileName() ?? requestContext.ToOutputFileName("mp3")
            },
            cancellationToken);

        if (string.IsNullOrWhiteSpace(typed.ReferVoice) && string.IsNullOrWhiteSpace(typed.ReferInstrumental))
            throw new ArgumentException("At least one of refer_voice or refer_instrumental is required.");

        // Step 2: Build JSON payload
        var body = new
        {
            model = "music-01",
            lyrics = typed.Lyrics,
            audio_setting = new
            {
                refer_voice = typed.ReferVoice,
                refer_instrumental = typed.ReferInstrumental
            }
        };

        var aiml = serviceProvider.GetRequiredService<AIMLClient>();
        var doc = await aiml.PostAsync(BASE_URL, body, cancellationToken);
        var id = doc.RootElement.TryGetProperty("id", out var idProp)
            ? idProp.GetString()
            : null;

        if (string.IsNullOrWhiteSpace(id))
            throw new Exception("No generation ID returned from MiniMax API.");

        return doc.ToJsonContent(MINIMAX_GENERATE_URL).ToCallToolResult();
    });

    // --- Enums & Request DTOs ---

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum UploadPurpose
    {
        [EnumMember(Value = "song")]
        Song,

        [EnumMember(Value = "voice")]
        Voice,

        [EnumMember(Value = "instrumental")]
        Instrumental
    }

    [Description("Please fill in the MiniMax upload request details.")]
    public class AIMLMiniMaxUploadRequest
    {
        [JsonPropertyName("fileUrl")]
        [Required]
        [Description("Input file URL to upload (MP3 or WAV).")]
        public string FileUrl { get; set; } = default!;

        [JsonPropertyName("purpose")]
        [Required]
        [Description("Purpose of the upload (song, voice, or instrumental).")]
        public UploadPurpose Purpose { get; set; } = UploadPurpose.Song;
    }

    [Description("Please fill in the MiniMax music generation details.")]
    public class AIMLMiniMaxGenerateRequest
    {
        [JsonPropertyName("lyrics")]
        [Required]
        [Description("Lyrics content for the generated song.")]
        public string Lyrics { get; set; } = default!;

        [JsonPropertyName("refer_voice")]
        [Description("Voice ID from the MiniMax upload step.")]
        public string? ReferVoice { get; set; }

        [JsonPropertyName("refer_instrumental")]
        [Description("Instrumental ID from the MiniMax upload step.")]
        public string? ReferInstrumental { get; set; }

        [JsonPropertyName("filename")]
        [Required]
        [Description("Output filename without extension.")]
        public string Filename { get; set; } = default!;
    }

    [Description("Generate an audio sample using StabilityAI's Stable Audio model. Suitable for ambient, instrumental, or sound design generation.")]
    [McpServerTool(
     Title = "Generate audio with Stable Audio",
     Name = "aiml_music_stableaudio_generate",
     Destructive = false)]
    public static async Task<CallToolResult?> AIMLMusic_StableAudioGenerate(
     [Description("Prompt describing the audio to generate (genre, mood, instruments, etc.)."), MaxLength(4000)] string prompt,
     IServiceProvider serviceProvider,
     RequestContext<CallToolRequestParams> requestContext,
     [Description("Start time of the audio in seconds (1–47)."), Range(1, 47)] int secondsStart = 1,
     [Description("Total duration of the audio clip in seconds (1–47)."), Range(1, 47)] int secondsTotal = 30,
     [Description("Number of denoising steps (1–1000). Higher = better quality, slower generation."), Range(1, 1000)] int steps = 100,
     [Description("Output filename without extension. Defaults to autogenerated name.")] string? filename = null,
     CancellationToken cancellationToken = default)
     => await requestContext.WithExceptionCheck(async () =>
 {
     var settings = serviceProvider.GetRequiredService<AIMLSettings>();
     var clientFactory = serviceProvider.GetRequiredService<IHttpClientFactory>();

     // Step 1: Ask user for missing input
     var (typed, notAccepted, _) = await requestContext.Server.TryElicit(
         new AIMLStableAudioRequest
         {
             Prompt = prompt,
             SecondsStart = secondsStart,
             SecondsTotal = secondsTotal,
             Steps = steps,
             Filename = filename?.ToOutputFileName() ?? requestContext.ToOutputFileName("wav")
         },
         cancellationToken);

     // Step 2: Build JSON payload
     var body = new
     {
         model = "stable-audio",
         prompt = typed.Prompt,
         seconds_start = typed.SecondsStart,
         seconds_total = typed.SecondsTotal,
         steps = typed.Steps
     };

     var aiml = serviceProvider.GetRequiredService<AIMLClient>();
     var doc = await aiml.PostAsync(BASE_URL, body, cancellationToken);

     var id = doc.RootElement.TryGetProperty("id", out var idProp)
         ? idProp.GetString()
         : null;

     if (string.IsNullOrWhiteSpace(id))
         throw new Exception("No generation ID returned from Stable Audio API.");

     return doc.ToJsonContent(BASE_URL).ToCallToolResult();
 });


    [Description("Please fill in the Stable Audio generation request.")]
    public class AIMLStableAudioRequest
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("Prompt describing the desired audio output.")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("seconds_start")]
        [Range(1, 47)]
        [Description("Start point of the generated audio clip (seconds).")]
        public int SecondsStart { get; set; } = 1;

        [JsonPropertyName("seconds_total")]
        [Range(1, 47)]
        [Description("Duration of the generated audio clip (seconds).")]
        public int SecondsTotal { get; set; } = 30;

        [JsonPropertyName("steps")]
        [Range(1, 1000)]
        [Description("Number of denoising steps (1–1000).")]
        public int Steps { get; set; } = 100;

        [JsonPropertyName("filename")]
        [Required]
        [Description("Output filename without extension.")]
        public string Filename { get; set; } = default!;
    }
}
