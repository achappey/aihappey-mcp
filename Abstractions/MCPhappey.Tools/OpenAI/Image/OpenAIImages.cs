using System.ComponentModel;
using System.ComponentModel.DataAnnotations;
using System.Runtime.Serialization;
using System.Text.Json.Serialization;
using MCPhappey.Common.Extensions;
using MCPhappey.Core.Extensions;
using MCPhappey.Core.Services;
using Microsoft.Extensions.DependencyInjection;
using ModelContextProtocol.Protocol;
using ModelContextProtocol.Server;
using OpenAI;
using OpenAI.Images;

namespace MCPhappey.Tools.OpenAI.Image;

public static class OpenAIImages
{
    [Description("Create an image with OpenAI image generator")]
    [McpServerTool(Title = "Generate image with OpenAI",
        ReadOnly = false,
        Idempotent = false,
        OpenWorld = true,
        Destructive = false)]
    public static async Task<CallToolResult?> OpenAIImages_CreateImage(
     [Description("The image prompt.")] string prompt,
     IServiceProvider serviceProvider,
     RequestContext<CallToolRequestParams> requestContext,
     [Description("Image generation model to use.")] Model model = Model.gpt_image_1_5,
     [Description("New image file name, without extension. Defaults to autogenerated filename.")] string? filename = null,
     [Description("Size of the image (auto, 1024x1024, 1536x1024 or 1024x1536). Defaults to auto.")] ImageSize? size = ImageSize.auto,
     [Description("Image quality: auto (default), high, medium or low.")] ImageQuality? quality = ImageQuality.auto,
     [Description("Background setting: auto (default), transparent, or opaque.")] ImageBackground? background = ImageBackground.auto,
     [Description("Content moderation level: auto (default) or low.")] ImageModerationLevel? moderation = ImageModerationLevel.auto,
     CancellationToken cancellationToken = default) =>
         await requestContext.WithExceptionCheck(async () =>
    {
        var openAiClient = serviceProvider.GetRequiredService<OpenAIClient>();
        var imageInput = new OpenAINewImage
        {
            Prompt = prompt,
            Model = model,
            Filename = filename ?? requestContext.ToOutputFileName("png"),
            Size = size ?? ImageSize.square,
            Quality = quality ?? ImageQuality.auto,
            Background = background ?? ImageBackground.auto,
            Moderation = moderation ?? ImageModerationLevel.auto
        };

        var (typed, _, _) = await requestContext.Server.TryElicit(imageInput, cancellationToken);

        var sizeValue = typed.Size switch
        {
            ImageSize.square => GeneratedImageSize.W1024xH1024,
            ImageSize.landscape => new GeneratedImageSize(1536, 1024),
            ImageSize.portrait => new GeneratedImageSize(1024, 1536),
            _ => GeneratedImageSize.Auto
        };

        var finalQuality = typed.Quality?.ToString();
        var generatedQuality = string.IsNullOrEmpty(finalQuality)
            ? GeneratedImageQuality.Auto : new GeneratedImageQuality(finalQuality);

        var resultImage = await openAiClient
            .GetImageClient(typed.Model.GetEnumMemberValue())
            .GenerateImageAsync(typed.Prompt, new()
            {
                Quality = generatedQuality,
                Size = sizeValue,
                Background = typed.Background?.ToString(),
                ModerationLevel = typed.Moderation?.ToString()
            }, cancellationToken);

        var uploaded = await requestContext.Server.Upload(
            serviceProvider,
            $"{typed.Filename}.png",
            resultImage.Value.ImageBytes,
            cancellationToken);

        return uploaded?.ToResourceLinkCallToolResponse();
    });

    [Description("Create an image edit with OpenAI image generator")]
    [McpServerTool(Title = "Generate an image edit with OpenAI",
        ReadOnly = false,
        Idempotent = false,
        OpenWorld = true,
        Destructive = false)]
    public static async Task<CallToolResult?> OpenAIImages_CreateImageEdit(
     [Description("The image prompt.")] string prompt,
     [Description("File url of the image that should be used for the edit. This tool can also access secured SharePoint and OneDrive links.")] string fileUrl,
     IServiceProvider serviceProvider,
     RequestContext<CallToolRequestParams> requestContext,
     [Description("Image generation model to use.")] Model model = Model.gpt_image_1_5,
     [Description("New image file name, without extension. Defaults to autogenerated filename.")] string? filename = null,
     [Description("Size of the image (auto, 1024x1024, 1536x1024 or 1024x1536). Defaults to auto.")] ImageSize? size = ImageSize.auto,
     [Description("Background setting: auto (default), transparent, or opaque.")] ImageBackground? background = ImageBackground.auto,
     [Description("Image quality: auto (default), high, medium or low.")] ImageQuality? quality = ImageQuality.auto,
     CancellationToken cancellationToken = default) =>
         await requestContext.WithExceptionCheck(async () =>
    {
        var openAiClient = serviceProvider.GetRequiredService<OpenAIClient>();
        var downloadService = serviceProvider.GetRequiredService<DownloadService>();

        var files = await downloadService.DownloadContentAsync(serviceProvider, requestContext.Server, fileUrl, cancellationToken);
        var image = files.FirstOrDefault();

        var imageInput = new OpenAINewImageEdit
        {
            Prompt = prompt,
            Model = model,
            Background = background ?? ImageBackground.auto,
            Quality = quality ?? ImageQuality.auto,
            Filename = filename ?? requestContext.ToOutputFileName("png"),
            Size = size ?? ImageSize.square,
        };

        var (typed, notAccepted, result) = await requestContext.Server.TryElicit(imageInput, cancellationToken);
        if (typed == null) return "Error".ToErrorCallToolResponse();

        var sizeValue = typed.Size switch
        {
            ImageSize.square => GeneratedImageSize.W1024xH1024,
            ImageSize.landscape => new GeneratedImageSize(1536, 1024),
            ImageSize.portrait => new GeneratedImageSize(1024, 1536),
            _ => GeneratedImageSize.Auto
        };

        var finalQuality = typed.Quality?.ToString();
        var generatedQuality = string.IsNullOrEmpty(finalQuality)
            ? GeneratedImageQuality.Auto : new GeneratedImageQuality(finalQuality);

        var resultImage = await openAiClient
           .GetImageClient(typed.Model.GetEnumMemberValue())
            .GenerateImageEditAsync(image?.Contents.ToStream(), image?.Filename, typed.Prompt, new()
            {
                Size = sizeValue,
                Background = typed.Background?.ToString(),
                Quality = generatedQuality,
            }, cancellationToken);

        var uploaded = await requestContext.Server.Upload(
            serviceProvider,
            $"{typed.Filename}.png",
            resultImage.Value.ImageBytes,
            cancellationToken);

        return uploaded?.ToResourceLinkCallToolResponse();
    });

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum ImageBackground
    {
        [Display(Name = "Auto")]
        auto,         // default

        [Display(Name = "Transparent")]
        transparent,  // requires png or webp

        [Display(Name = "Opaque")]
        //[Display(Name = "Opaque")]
        opaque
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum ImageModerationLevel
    {
        [Display(Name = "Auto")]
        auto,  // default

        [Display(Name = "Low")]
        low    // less restrictive filtering
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum ImageQuality
    {
        [Display(Name = "Auto")]
        auto,

        [Display(Name = "High")]
        high,

        [Display(Name = "Medium")]
        medium,

        [Display(Name = "Low")]
        low
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum Model
    {
        [EnumMember(Value = "chatgpt-image-latest")]
        [Display(Name = "chatgpt-image-latest")]
        chatgpt_image_latest,

        [EnumMember(Value = "gpt-image-1.5")]
        [Display(Name = "gpt-image-1.5")]
        gpt_image_1_5,

        [EnumMember(Value = "gpt-image-1")]
        [Display(Name = "gpt-image-1")]
        gpt_image_1,

        [EnumMember(Value = "gpt-image-1-mini")]
        [Display(Name = "gpt-image-1-mini")]
        gpt_image_1_mini,
    }

    [JsonConverter(typeof(JsonStringEnumConverter))]
    public enum ImageSize
    {
        [Display(Name = "Auto")]
        auto,

        // [EnumMember(Value = "1024x1024")]
        [Display(Name = "Square")]
        square,

        // [EnumMember(Value = "1536x1024")]
        [Display(Name = "Landscape")]
        landscape,

        // [EnumMember(Value = "1024x1536")]
        [Display(Name = "Portrait")]
        portrait
    }



    [Description("Please fill in the AI image request details.")]
    public class OpenAINewImage
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("The image prompt.")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("filename")]
        [Required]
        [Description("The image file name.")]
        public string Filename { get; set; } = default!;

        [JsonPropertyName("model")]
        [Required]
        [JsonConverter(typeof(JsonStringEnumConverter))]
        [Description("Image model to use.")]
        public Model Model { get; set; }

        [JsonPropertyName("background")]
        [JsonConverter(typeof(JsonStringEnumConverter))]
        [Description("The background setting: auto (default), transparent, or opaque.")]
        public ImageBackground? Background { get; set; }

        [JsonPropertyName("moderation")]
        [JsonConverter(typeof(JsonStringEnumConverter))]
        [Description("The content moderation level: auto (default) or low.")]
        public ImageModerationLevel? Moderation { get; set; }

        [JsonPropertyName("quality")]
        [JsonConverter(typeof(JsonStringEnumConverter))]
        [Description("The image quality: auto (default), high, medium, or low.")]
        public ImageQuality? Quality { get; set; }

        [JsonPropertyName("size")]
        [JsonConverter(typeof(JsonStringEnumConverter))]
        [Description("The image size: auto (default), 1024x1024, 1536x1024, or 1024x1536.")]
        public ImageSize? Size { get; set; }
    }


    [Description("Please fill in the AI image request details.")]
    public class OpenAINewImageEdit
    {
        [JsonPropertyName("prompt")]
        [Required]
        [Description("The image prompt.")]
        public string Prompt { get; set; } = default!;

        [JsonPropertyName("filename")]
        [Required]
        [Description("The new image file name.")]
        public string Filename { get; set; } = default!;

        [JsonPropertyName("model")]
        [Required]
        [JsonConverter(typeof(JsonStringEnumConverter))]
        [Description("Image model to use.")]
        public Model Model { get; set; }

        [JsonPropertyName("size")]
        [JsonConverter(typeof(JsonStringEnumConverter))]
        [Description("The image size: auto (default), 1024x1024, 1536x1024, or 1024x1536.")]
        public ImageSize? Size { get; set; }

        [JsonPropertyName("background")]
        [JsonConverter(typeof(JsonStringEnumConverter))]
        [Description("The background setting: auto (default), transparent, or opaque.")]
        public ImageBackground? Background { get; set; }

        [JsonPropertyName("quality")]
        [JsonConverter(typeof(JsonStringEnumConverter))]
        [Description("The image quality: auto (default), high, medium, or low.")]
        public ImageQuality? Quality { get; set; }

    }
}

